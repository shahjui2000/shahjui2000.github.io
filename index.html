<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Jui Shah</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">
  <link rel="shortcut icon" href=" " type="image/x-icon"/>


  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: iPortfolio - v1.2.1
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169610023-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-169610023-1');
  </script>

</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/profile-img.png" alt="" class="img-fluid rounded-circle" style="width: 80% ;height:40% ;">
        <h1 class="text-light"><a href="index.html">Jui Shah</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://www.linkedin.com/in/jui-shah-241845166/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://github.com/shahjui2000" class="github"><i class="bx bxl-github"></i></a>
           <a href="https://scholar.google.com/citations?user=WfQ1Hf0AAAAJ&hl=en" class="google"><i class="bx bxl-google"></i></a>
        </div>
      </div>

      <nav class="nav-menu">
        <ul>
          <!-- <li><a href="#hero"><i class="bx bx-home"></i> <span>Home</span></a></li> -->
          <li><a href="#about"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="#resume"><i class="bx bx-file-blank"></i> <span>Publications</span></a></li>
<!--           <li><a href="#portfolio"><i class="bx bx-book-content"></i><span>Resume</span></a></li> -->
          <!-- <li><a href="#blog"><i class="bx bx-server"></i> Blog</a></li> -->
          <li><a href="#contact"><i class="bx bx-envelope"></i><span>Connect with me!</span></a></li>

        </ul>
      </nav><!-- .nav-menu -->
      <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

    </div>
  </header><!-- End Header -->

  

  <main id="main">

    <!-- ======= Hero Section ======= -->
    <!-- <section id="hero" class="d-flex flex-column justify-content-center align-items-center">
      <div class="hero-container" data-aos="fade-in">
        <h1>Jui Shah</h1>
        <p>I'm <span class="typed" data-typed-items="Designer, Developer, Freelancer, Photographer"></span></p>
      </div>
    </section> --> 
    <!-- End Hero --> 

    <!-- ======= About Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
          <h2>About Me</h2>
          <p>MS CS student at UMass-Amherst. Always looking forward to connecting! 

            A little about me - I prefer to constantly learn something new over being free.
            I like ML based projects and research. So far I have 6 publications and 31 citations 
            on topics belonging to a variety of domains including speech, audio, multimodal domains,
            cyber-security and robotics. My technical internship at Linkedin has helped me implement my 
            ML knowledge at the industry level and that at Deutsche Bank has exposed me to the world of fin-tech. 
            <br>
            Overall, my experience even before entering as a FTE has been very diverse with technology including
            the amazing people I have worked with, the type of institutions or companies I have worked with and
            it has been great navigating through all of them. Can't wait for what's next - Seeking FTE roles starting next year!
          </p>
          <br>
          <a role="button" class="btn btn-primary" href="#resume">Publications</a>
          <a role="button" class="btn btn-secondary" href="#portfolio">Resume </a>
          
        </div>
      </div>
    </section>

<!--     <section id="portfolio2" class="portfolio section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Projects done during undergrad</h2>
          <div class="row">
            <div class="col-lg-6">
              <ul>
                <li> Deep Learning/Machine Learning (DL/ML) </li>
                <li> <strong> Speech Tech: </strong> DL in Voice Conversion, Music Conversion, Zero-Shot Learning </li>
                <li> DL for a Robotic Manipulator Arm </li>
                <li> <strong>Cyber Security:</strong> DL in Intrusion Detection </li>
                <li> <strong>Explainable AI:</strong> Interpreting transformers(working currently) </li>

              </ul>
            </div>
            <div class="col-lg-6">
              <ul>
                <li> <strong>Full-stack development</strong> : MEAN Stack (MongoDB, Express, Angular, Node) </li>
                <li> <strong>Agile Methodology</strong>: CI-CD, Karma-Jasmine Unit Testing, e2e Testing: Protractor </li>
                <li> Media-Content DataBase Managment System(Netflix like) </li>
                <li> Bellman Ford - High Performance Computing Analysis </li>
              </ul>
            </div>
          </div>
        </div>
      </div>     
         -->
    </section>
<!--           
          <div class="col-lg-8 pt-4 pt-lg-0 content" data-aos="fade-left" >
            <h3></h3> -->
            <!-- <p class="font-italic">
              
            </p>
            
          </div>
        </div> --> 
        

        <!-- <div class="section-title">
        <h2>Key Accolades</h2>
        <p> 
          <ul>
            <li>Recieved Merit Scholarship for entire B.Tech tution fees based on admission rank within top 5 of the institute
               and SPI(Semester Performance Index) of above 8 each semester to be eligible for scholarship of the next semseter. </li>
            <li>AIR(All-India Rank) of 2226 in JEE MAINS out of 11,98,989 students who gave the exam. <strong>In the top 0.18% of
               engineering students</strong> in this national entrance examination.</li>
            <li>AIR(All-India Rank) of 4356 in JEE Advanced out of the total 2,21,427 students who gave the exam for entrance to 
              India's top-tier institution -IITs. <strong>In the top 1.96% of students who appeared.</strong> 
              <i>Though, I could only get branches other than CS in the top IITs and hence, I chose the branch over IIT tag.</i>
             </li>
             <li>Getting a paper published in ICASSP at the third year of undergrad itself.</li>
          </ul>
        </p>
      </div> -->
      

    <!-- ======= Resume Section ======= -->
    <section id="resume" class="resume">
      <div class="container">

        <div class="section-title">
          <h2>Publications</h2>
        </div>

          <div class="resume-item pb-0">
            <h4>What all do audio transformer models hear? Probing Acoustic Representations for Language Delivery and its Structure</h4>

                <ul>
                  <li>Preprint on arxiv</li>
                  <li> 2021 </li>
                  <li> <a href ="https://arxiv.org/abs/2101.00387">Paper</a> </li>
                </ul>
            <div data-aos="fade-up">

<!--               <img src="assets/img/MSpecNet.png" class="TextWrap" alt=""style="width: 100% ;height:30% ;"> -->

              <p><em>In recent times, BERT based transformer models have become an inseparable part of the 'tech stack' of text processing models.
                Similar progress is being observed in the speech domain with a multitude of models observing state-of-the-art results by using audio
                transformer models to encode speech. This begs the question of what are these audio transformer models learning. Moreover, although
                the standard methodology is to choose the last layer embedding for any downstream task, but is it the optimal choice? We try to answer
                these questions for the two recent audio transformer models, Mockingjay and wave2vec2.0. We compare them on a comprehensive set
                of language delivery and structure features including audio, fluency and pronunciation features. Additionally, we probe the
                audio models' understanding of textual surface, syntax, and semantic features and compare them to BERT. We do this over
                exhaustive settings for native, non-native, synthetic, read and spontaneous speech datasets.
                </em></p>
                <br>
            </div>
          </div>
        
          <div class="resume-item pb-0">
            <h4>MSPEC-NET : MULTI-DOMAIN SPEECH CONVERSION NETWORK</h4>

                <ul>
                  <li>45th International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2020</li>
                  <li>IEEE | May 4-8,2020</li>
                  <li> <a href ="https://ieeexplore.ieee.org/document/9052966">Paper</a>  | <a href="https://maitreyapatel.github.io/mspec-net-demo/">Demo</a> | <a href="https://github.com/Maitreyapatel/speech-conversion-between-different-modalities"> Code</a>  </li>
                </ul>
            <div data-aos="fade-up">

              <img src="assets/img/MSpecNet.png" class="TextWrap" alt=""style="width: 100% ;height:30% ;">

              <p><em>In this paper, we present a multi-domain speech conversion technique by proposing a Multi-domain Speech
                Conversion Network (MSpeC-Net) architecture for solving the less-explored area of Non-Audible Murmur-to-SPeeCH
                  (NAM2-SPCH) conversion. The murmur produced by the speaker and captured by the NAM microphone undergoes speech
                  quality degradation. Hence, NAM2SPCH conversion becomes a necessary and challenging task for improving the 
                  intelligibility of NAM signal. MSpeC-Net contains three domain-specific autoencoders. The multiple encoder-decoders 
                  are aligned using latent consistency loss in such a way that the desired conversion is achieved by using the source
                  encoder and target decoder only. We have performed zero-pair NAM2SPCH conversion using the interaction between source 
                  encoder and the target decoder. We evaluated our proposed method using both objective and subjective evaluations. With
                    a Mean Opinion Score of 3.26 and 3.12 on an average in a direct NAM2SPCH, and an indirect NAM2SPCH (i.e., 
                    NAM-to-whisper-to-speech) conversion, respectively. MSpeC-Net achieves the perceptually significant improvement for NAM2SPCH conversion system.</em></p>
              <!-- <div class="col-lg-9" data-aos="fade-up">            -->
                <br>
            </div>
          </div>

          <div class="resume-item pb-0">
            <h4> CinC-GAN for Effective F0 predictionfor Whisper-to-Normal Speech Conversion
            </h4>
            <ul>
              <li>28th European Signal Processing Conference (EUSIPCO), IEEE</li>
              <li>IEEE | Jan 18-22,2021</li>
              <li> Paper </li>                
            </ul>
            <div class="row">
              <div class="col-lg-6" data-aos="fade-up"> 
                <img src="assets/img/CinCGAN.png" class="TextWrap" alt=""style="width: 100% ;height:80% ;">
              </div> 
              <div class="col-lg-6" data-aos="fade-up">
                <p><em>Recently, Generative Adversarial Networks (GAN)-based methods have shown remarkable performance 
                for the Voice Conversion and WHiSPer-to-normal SPeeCH (WHSP2SPCH) conversion. One of the key challenges
                in WHSP2SPCH conversion is the prediction of fundamental frequency (F0). Recently, authors have proposed
                state-of-the-art method Cycle-Consistent Generative Adversarial Networks (CycleGAN) for WHSP2SPCH conversion.
                The CycleGAN-based method uses two different models, one for Mel Cepstral Coefficients (MCC) mapping, and
                another for F0 prediction, where F0 is highly dependent on the pre-trained model of MCC mapping. This leads
                to additional non-linear noise in predicted $F_0$. To suppress this noise, we propose Cycle-in-Cycle GAN 
                (i.e., CinC-GAN). It is specially designed to increase the effectiveness in F0 prediction without losing 
                the accuracy of MCC mapping. We evaluated the proposed method on a non-parallel setting and analyzed on
                speaker-specific, and gender-specific tasks. The objective and subjective tests show that CinC-GAN significantly 
                outperforms the CycleGAN. In addition, we analyze the CycleGAN and CinC-GAN for unseen speakers and the results
                show the clear superiority of CinC-GAN.</em></p><br>
              </div>
            </div>
          </div>


          <div class="resume-item pb-0">
            <h4> Effectiveness of Transfer Learning on Singing Voice Conversion in the Presence of Background Music
            </h4>
            <ul>
              <li> International Conference on Signal Processing and Communication (SPCOM) 2020 </li>
              <li>IEEE | Jul 20-23,2020</li>
              <li> Paper </li>                
            </ul>
            <div class="row">              
              <div class="col-lg-6" data-aos="fade-up">
                <p><em>Singing voice conversion (SVC) is a task of converting the perception of source speaker’s identity to target 
                  speaker without changing lyrics and rhythm. Recent approaches in traditional voice conversion involves the use of 
                  the generative models, such as Autoencoders (AE), Variational Autoencoders (VAE), and Generative Adversarial Networks 
                  (GANs). However, in case of SVC, GANs are not explored much. The only system that has been proposed in the literature u
                  ses traditional GAN on the parallel data. The parallel data collection for real scenarios (with the same background music)
                  is not feasible at all. Moreover, SVC in the presence of background music is one of the most challenging tasks as it involves 
                  the source separation of vocals from the inputs, which will have some amount of noise. Therefore, in this paper, we propose 
                  transfer learning, and fine-tuning-based Cycle consistent GAN (CycleGAN) model for non-parallel SVC, where music source 
                  separation is done using Deep Atrractor Network (DANet). We designed seven different possible scenarios to identify the 
                  best possible combination of transfer learning and fine-tuning. Here, we use more challenging database, MUSDB18, as our 
                  primary dataset. And, we use NUS-48E database to pretrain CycleGAN. We perform extensive analysis via objective and 
                  subjective measures and report that with a 4.14 MOS score out of 5 for naturalness, the CycleGAN model pretrained on
                    NUS-48E corpus performs the best compared to the other systems we have described in the paper.</em></p><br>
              </div>
              <div class="col-lg-6" data-aos="fade-up">
                <img src="assets/img/singing_diagram.png" class="TextWrap" alt=""style="width: 100% ;height:30% ;">
                <img src="assets/img/CycleGAN.png" class="TextWrap" alt=""style="width: 100% ;height:50% ;">
              </div>
            </div>
          </div>

          <div class="resume-item pb-0">
          <h4> Real-Time Neural-Net Driven Optimized Inverse Kinematics for a Robotic Manipulator Arm
          </h4>

              <ul>
                <li> International Conference on Advanced Machine Learning Technologies and Applications (AMLTA) 2020 </li>
                <li>Springer | Feb 13-15,2020</li>
                <li> <a href="https://link.springer.com/chapter/10.1007%2F978-981-15-3383-9_7">Paper</a> </li>                
              </ul>
              <div class="row">              
                <div class="col-lg-6" data-aos="fade-up">
                  <img src="assets/img/amlta2.png" alt=""style="width: 100% ;height:45% ;">
                  <!-- <br> -->
                  <img src="assets/img/AMLTA.png" alt=""style="width: 100% ;height:45% ;">
                </div>
                <div class="col-lg-6" data-aos="fade-up">
                  <p><em>This paper proposes a method that optimizes the inverse kinematics needed for the 
                    trajectory generation of a 4-DOF (degrees of freedom) robotic manipulator arm to give 
                    results in real time. Due to the many-to-one mapping of the angle vector which describes
                    the position of the manipulator joints and to the coordinates of the end-effector, traditional
                      methods fail to address the redundancy that exists in an efficient way. The proposed method 
                      is singular, and in that it (1) Generates the most optimal angle vector in terms of maximum
                      manipulability, a factor which determines the ease with which the arm moves, for a given
                        end-vector. (2) Proposes a novel approach to inculcate the complexity of dealing with real 
                        coordinate system by proposing a machine learning technique that uses neural networks to
                        predict angle vector for practically any end-effector position although it learns on only 
                        a few sampled space. (3) Works in real time since the entire optimization of the manipulability
                          measure are done offline before training the neural network using a relevant technique which
                          makes the proposed method suitable for practical uses. (4) It also determines the shortest,
                            smooth path along which the manipulator can move along avoiding any obstacles. To the best 
                            of the authors’ knowledge, this is the first neural-net-based optimized inverse kinematics
                            method applied for a robotic manipulator arm, and its optimal and simple structure also
                              makes it possible to run it on NVIDIA Jetson Nano Module.</em></p><br>
                </div>
              </div>
          </div>

          
      </div>
    </section><!-- End Resume Section -->

    <!-- ======= Portfolio Section ======= -->
<!--     <section id="portfolio" class="portfolio section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Resume</h2>
          
          <object data="resume.pdf" type="application/pdf" height=1000 width="100%">
            <a href="resume.pdf">Your browser does not support this pdf. Click to download instead.</a>
            </object>

            
        </div>

        
    </section> -->

    

    <!-- ======= Contact Section ======= -->
    <section id="contact" class="contact">
      <div class="container">

        <div class="section-title">
          <h2>Connect @</h2>
        </div>

        <div class="row" data-aos="fade-in">

          <div class="col-lg-5 d-flex align-items-stretch">
            <div class="info">
              

              <div class="email">
                <i class="icofont-envelope"></i>
                <h4>Email:</h4>
                <p>shahjui2000@gmail.com</p>
              </div>

              <div class="email">
                <i class="icofont-envelope"></i>
                <h4>University Email:</h4>
                <p>jui_shah@daiict.ac.in</p>
              </div>

            </div>

          </div>

          <div class="col-lg-7 mt-5 mt-lg-0 d-flex align-items-stretch">  
            <div class="info">

              <div class="email">
                <i class="bx bxl-linkedin"></i>
                <h4>LinkedIn</h4>
                <p> <a href="https://www.linkedin.com/in/jui-shah-241845166/">Jui Shah</a></p>
              </div>

              <div class="email">
                <i class="bx bxl-github"></i>
                <h4>GitHub</h4>
                <p> <a href="https://github.com/shahjui2000" >shahjui2000</a></p>
              </div>

              <div class="email">
                <i class="bx bxl-twitter"></i>
                <h4>Twitter</h4>
                <p> <a href="https://twitter.com/JuiShah20" >JuiShah20</a></p>
              </div>

            </div>
          </div>

        </div>

      </div>
    </section><!-- End Contact Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>iPortfolio</span></strong>
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a> | Modified by Jui Shah
        <!-- <br>Modified by <strong>Jui Shah</strong> -->
      </div>
    </div>
  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
